"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.StreamsWriterV2 = void 0;
const streamstore_1 = require("@s2-dev/streamstore");
const nanoid_1 = require("nanoid");
/**
 * StreamsWriterV2 writes metadata stream data directly to S2 (https://s2.dev).
 *
 * Features:
 * - Direct streaming: Uses S2's appendSession for efficient streaming
 * - Automatic batching: Uses BatchTransform to batch records
 * - No manual buffering: S2 handles buffering internally
 * - Debug logging: Enable with debug: true to see detailed operation logs
 *
 * Example usage:
 * ```typescript
 * const stream = new StreamsWriterV2({
 *   basin: "my-basin",
 *   stream: "my-stream",
 *   accessToken: "s2-token-here",
 *   source: myAsyncIterable,
 *   flushIntervalMs: 200, // Optional: batch linger duration in ms
 *   debug: true, // Optional: enable debug logging
 * });
 *
 * // Wait for streaming to complete
 * await stream.wait();
 *
 * // Or consume the stream
 * for await (const value of stream) {
 *   console.log(value);
 * }
 * ```
 */
class StreamsWriterV2 {
    options;
    s2Client;
    serverStream;
    consumerStream;
    streamPromise;
    flushIntervalMs;
    debug;
    maxQueuedBytes;
    aborted = false;
    sessionWritable = null;
    constructor(options) {
        this.options = options;
        this.debug = options.debug ?? false;
        this.s2Client = new streamstore_1.S2({ accessToken: options.accessToken });
        this.flushIntervalMs = options.flushIntervalMs ?? 200;
        this.maxQueuedBytes = options.maxQueuedBytes ?? 1024 * 1024 * 10; // 10MB default
        this.log(`[S2MetadataStream] Initializing: basin=${options.basin}, stream=${options.stream}, flushIntervalMs=${this.flushIntervalMs}, maxQueuedBytes=${this.maxQueuedBytes}`);
        // Check if already aborted
        if (options.signal?.aborted) {
            this.aborted = true;
            this.log("[S2MetadataStream] Signal already aborted, skipping initialization");
            this.serverStream = new ReadableStream();
            this.consumerStream = new ReadableStream();
            this.streamPromise = Promise.resolve();
            return;
        }
        // Set up abort signal handler
        if (options.signal) {
            options.signal.addEventListener("abort", () => {
                this.log("[S2MetadataStream] Abort signal received");
                this.handleAbort();
            });
        }
        const [serverStream, consumerStream] = this.options.source.tee();
        this.serverStream = serverStream;
        this.consumerStream = consumerStream;
        this.streamPromise = this.initializeServerStream();
    }
    handleAbort() {
        if (this.aborted) {
            return; // Already aborted
        }
        this.aborted = true;
        this.log("[S2MetadataStream] Handling abort - cleaning up resources");
        // Abort the writable stream if it exists
        if (this.sessionWritable) {
            this.sessionWritable
                .abort("Aborted")
                .catch((error) => {
                this.logError("[S2MetadataStream] Error aborting writable stream:", error);
            })
                .finally(() => {
                this.log("[S2MetadataStream] Writable stream aborted");
            });
        }
        this.log("[S2MetadataStream] Abort cleanup complete");
    }
    async initializeServerStream() {
        try {
            if (this.aborted) {
                this.log("[S2MetadataStream] Stream initialization aborted");
                return;
            }
            this.log("[S2MetadataStream] Getting S2 basin and stream");
            const basin = this.s2Client.basin(this.options.basin);
            const stream = basin.stream(this.options.stream);
            const session = await stream.appendSession({
                maxQueuedBytes: this.maxQueuedBytes,
            });
            this.sessionWritable = session.writable;
            this.log(`[S2MetadataStream] Starting stream pipeline`);
            // Convert source stream to AppendRecord format and pipe to S2
            await this.serverStream
                .pipeThrough(new TransformStream({
                transform: (chunk, controller) => {
                    if (this.aborted) {
                        controller.error(new Error("Stream aborted"));
                        return;
                    }
                    // Convert each chunk to JSON string and wrap in AppendRecord
                    controller.enqueue(streamstore_1.AppendRecord.make(JSON.stringify({ data: chunk, id: (0, nanoid_1.nanoid)(7) })));
                },
            }))
                .pipeThrough(new streamstore_1.BatchTransform({
                lingerDurationMillis: this.flushIntervalMs,
            }))
                .pipeTo(session.writable);
            this.log("[S2MetadataStream] Stream pipeline completed successfully");
            // Get final position to verify completion
            const lastAcked = session.lastAckedPosition();
            if (lastAcked?.end) {
                const recordsWritten = lastAcked.end.seq_num;
                this.log(`[S2MetadataStream] Written ${recordsWritten} records, ending at seq_num=${lastAcked.end.seq_num}`);
            }
        }
        catch (error) {
            if (this.aborted) {
                this.log("[S2MetadataStream] Stream error occurred but stream was aborted");
                return;
            }
            this.logError("[S2MetadataStream] Error in stream pipeline:", error);
            throw error;
        }
    }
    async wait() {
        await this.streamPromise;
    }
    [Symbol.asyncIterator]() {
        return streamToAsyncIterator(this.consumerStream);
    }
    // Helper methods
    log(message) {
        if (this.debug) {
            console.log(message);
        }
    }
    logError(message, error) {
        if (this.debug) {
            console.error(message, error);
        }
    }
}
exports.StreamsWriterV2 = StreamsWriterV2;
async function* streamToAsyncIterator(stream) {
    const reader = stream.getReader();
    try {
        while (true) {
            const { done, value } = await reader.read();
            if (done)
                return;
            yield value;
        }
    }
    finally {
        safeReleaseLock(reader);
    }
}
function safeReleaseLock(reader) {
    try {
        reader.releaseLock();
    }
    catch (error) { }
}
//# sourceMappingURL=streamsWriterV2.js.map