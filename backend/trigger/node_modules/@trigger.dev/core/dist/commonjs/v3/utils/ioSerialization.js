"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.parsePacket = parsePacket;
exports.parsePacketAsJson = parsePacketAsJson;
exports.conditionallyImportAndParsePacket = conditionallyImportAndParsePacket;
exports.stringifyIO = stringifyIO;
exports.conditionallyExportPacket = conditionallyExportPacket;
exports.packetRequiresOffloading = packetRequiresOffloading;
exports.conditionallyImportPacket = conditionallyImportPacket;
exports.resolvePresignedPacketUrl = resolvePresignedPacketUrl;
exports.createPacketAttributes = createPacketAttributes;
exports.createPacketAttributesAsJson = createPacketAttributesAsJson;
exports.prettyPrintPacket = prettyPrintPacket;
exports.replaceSuperJsonPayload = replaceSuperJsonPayload;
const path_1 = require("@jsonhero/path");
const zod_1 = require("zod");
const apiClientManager_api_js_1 = require("../apiClientManager-api.js");
const limits_js_1 = require("../limits.js");
const semanticInternalAttributes_js_1 = require("../semanticInternalAttributes.js");
const zodfetch_js_1 = require("../zodfetch.js");
const flattenAttributes_js_1 = require("./flattenAttributes.js");
const superjson_js_1 = __importDefault(require("../imports/superjson.js"));
async function parsePacket(value, options) {
    if (!value.data) {
        return undefined;
    }
    switch (value.dataType) {
        case "application/json":
            return JSON.parse(value.data, makeSafeReviver(options));
        case "application/super+json":
            return superjson_js_1.default.parse(value.data);
        case "text/plain":
            return value.data;
        case "application/store":
            throw new Error(`Cannot parse an application/store packet (${value.data}). Needs to be imported first.`);
        default:
            return value.data;
    }
}
async function parsePacketAsJson(value, options) {
    if (!value.data) {
        return undefined;
    }
    switch (value.dataType) {
        case "application/json":
            return JSON.parse(value.data, makeSafeReviver(options));
        case "application/super+json":
            const superJsonResult = superjson_js_1.default.parse(value.data);
            const { json } = superjson_js_1.default.serialize(superJsonResult);
            return json;
        case "text/plain":
            return value.data;
        case "application/store":
            throw new Error(`Cannot parse an application/store packet (${value.data}). Needs to be imported first.`);
        default:
            return value.data;
    }
}
async function conditionallyImportAndParsePacket(value, client) {
    const importedPacket = await conditionallyImportPacket(value, undefined, client);
    return await parsePacket(importedPacket);
}
async function stringifyIO(value) {
    if (value === undefined) {
        return { dataType: "application/json" };
    }
    if (typeof value === "string") {
        return { data: value, dataType: "text/plain" };
    }
    try {
        const data = superjson_js_1.default.stringify(value);
        return { data, dataType: "application/super+json" };
    }
    catch {
        return { data: value, dataType: "application/json" };
    }
}
async function conditionallyExportPacket(packet, pathPrefix, tracer) {
    if (apiClientManager_api_js_1.apiClientManager.client) {
        const { needsOffloading, size } = packetRequiresOffloading(packet);
        if (needsOffloading) {
            if (!tracer) {
                return await exportPacket(packet, pathPrefix);
            }
            else {
                const result = await tracer.startActiveSpan("store.uploadOutput", async (span) => {
                    return await exportPacket(packet, pathPrefix);
                }, {
                    attributes: {
                        byteLength: size,
                        [semanticInternalAttributes_js_1.SemanticInternalAttributes.STYLE_ICON]: "cloud-upload",
                    },
                });
                return result ?? packet;
            }
        }
    }
    return packet;
}
function packetRequiresOffloading(packet, lengthLimit) {
    if (!packet.data) {
        return {
            needsOffloading: false,
            size: 0,
        };
    }
    const byteSize = Buffer.byteLength(packet.data, "utf8");
    return {
        needsOffloading: byteSize >= (lengthLimit ?? limits_js_1.OFFLOAD_IO_PACKET_LENGTH_LIMIT),
        size: byteSize,
    };
}
const ioRetryOptions = {
    minTimeoutInMs: 500,
    maxTimeoutInMs: 5000,
    maxAttempts: 5,
    factor: 2,
    randomize: true,
};
async function exportPacket(packet, pathPrefix) {
    // Offload the output
    const filename = `${pathPrefix}.${getPacketExtension(packet.dataType)}`;
    const presignedResponse = await apiClientManager_api_js_1.apiClientManager.client.createUploadPayloadUrl(filename);
    const uploadResponse = await (0, zodfetch_js_1.zodfetch)(zod_1.z.any(), presignedResponse.presignedUrl, {
        method: "PUT",
        headers: {
            "Content-Type": packet.dataType,
        },
        body: packet.data,
    }, {
        retry: ioRetryOptions,
    }).asResponse();
    if (!uploadResponse.ok) {
        throw new Error(`Failed to upload output to ${presignedResponse.presignedUrl}: ${uploadResponse.statusText}`);
    }
    return {
        data: filename,
        dataType: "application/store",
    };
}
async function conditionallyImportPacket(packet, tracer, client) {
    if (packet.dataType !== "application/store") {
        return packet;
    }
    if (!tracer) {
        return await importPacket(packet, undefined, client);
    }
    else {
        const result = await tracer.startActiveSpan("store.downloadPayload", async (span) => {
            return await importPacket(packet, span, client);
        }, {
            attributes: {
                [semanticInternalAttributes_js_1.SemanticInternalAttributes.STYLE_ICON]: "cloud-download",
            },
        });
        return result ?? packet;
    }
}
async function resolvePresignedPacketUrl(url, tracer) {
    try {
        const response = await fetch(url);
        if (!response.ok) {
            return;
        }
        const data = await response.text();
        const dataType = response.headers.get("content-type") ?? "application/json";
        const packet = {
            data,
            dataType,
        };
        return await parsePacket(packet);
    }
    catch (error) {
        return;
    }
}
async function importPacket(packet, span, client) {
    if (!packet.data) {
        return packet;
    }
    const $client = client ?? apiClientManager_api_js_1.apiClientManager.client;
    if (!$client) {
        return packet;
    }
    const presignedResponse = await $client.getPayloadUrl(packet.data);
    const response = await (0, zodfetch_js_1.zodfetch)(zod_1.z.any(), presignedResponse.presignedUrl, undefined, {
        retry: ioRetryOptions,
    }).asResponse();
    if (!response.ok) {
        throw new Error(`Failed to import packet ${presignedResponse.presignedUrl}: ${response.statusText}`);
    }
    const data = await response.text();
    span?.setAttribute("size", Buffer.byteLength(data, "utf8"));
    return {
        data,
        dataType: response.headers.get("content-type") ?? "application/json",
    };
}
async function createPacketAttributes(packet, dataKey, dataTypeKey) {
    if (!packet.data) {
        return;
    }
    switch (packet.dataType) {
        case "application/json":
            return {
                ...(0, flattenAttributes_js_1.flattenAttributes)(packet, dataKey),
                [dataTypeKey]: packet.dataType,
            };
        case "application/super+json":
            if (typeof packet.data === "undefined" || packet.data === null) {
                return;
            }
            try {
                const parsed = superjson_js_1.default.parse(packet.data);
                const jsonified = JSON.parse(JSON.stringify(parsed, makeSafeReplacer()));
                const result = {
                    ...(0, flattenAttributes_js_1.flattenAttributes)(jsonified, dataKey),
                    [dataTypeKey]: "application/json",
                };
                return result;
            }
            catch (e) {
                return;
            }
        case "application/store":
            return {
                [dataKey]: packet.data,
                [dataTypeKey]: packet.dataType,
            };
        case "text/plain":
            return {
                [dataKey]: packet.data,
                [dataTypeKey]: packet.dataType,
            };
        default:
            return;
    }
}
async function createPacketAttributesAsJson(data, dataType) {
    if (typeof data === "string" ||
        typeof data === "number" ||
        typeof data === "boolean" ||
        data === null ||
        data === undefined) {
        return data;
    }
    switch (dataType) {
        case "application/json": {
            return (0, limits_js_1.imposeAttributeLimits)((0, flattenAttributes_js_1.flattenAttributes)(data, undefined, limits_js_1.OTEL_SPAN_ATTRIBUTE_COUNT_LIMIT));
        }
        case "application/super+json": {
            const deserialized = superjson_js_1.default.deserialize(data);
            const jsonify = safeJsonParse(JSON.stringify(deserialized, makeSafeReplacer()));
            return (0, limits_js_1.imposeAttributeLimits)((0, flattenAttributes_js_1.flattenAttributes)(jsonify, undefined, limits_js_1.OTEL_SPAN_ATTRIBUTE_COUNT_LIMIT));
        }
        case "application/store": {
            return data;
        }
        default: {
            return {};
        }
    }
}
async function prettyPrintPacket(rawData, dataType, options) {
    if (rawData === undefined) {
        return "";
    }
    if (dataType === "application/super+json") {
        if (typeof rawData === "string") {
            rawData = safeJsonParse(rawData);
        }
        const hasCircularReferences = rawData && rawData.meta && hasCircularReference(rawData.meta);
        if (hasCircularReferences) {
            return await prettyPrintPacket(superjson_js_1.default.deserialize(rawData), "application/json", {
                ...options,
                cloneReferences: false,
            });
        }
        return await prettyPrintPacket(superjson_js_1.default.deserialize(rawData), "application/json", {
            ...options,
            cloneReferences: true,
        });
    }
    if (dataType === "application/json") {
        if (typeof rawData === "string") {
            rawData = safeJsonParse(rawData);
        }
        try {
            return JSON.stringify(rawData, makeSafeReplacer(options), 2);
        }
        catch (error) {
            // If cloneReferences is true, it's possible if our hasCircularReference logic is incorrect that stringifying the data will fail with a circular reference error
            // So we will try to stringify the data with cloneReferences set to false
            if (options?.cloneReferences) {
                return JSON.stringify(rawData, makeSafeReplacer({ ...options, cloneReferences: false }), 2);
            }
            throw error;
        }
    }
    if (typeof rawData === "string") {
        return rawData;
    }
    return JSON.stringify(rawData, makeSafeReplacer(options), 2);
}
function makeSafeReplacer(options) {
    const seen = new WeakSet();
    return function replacer(key, value) {
        if (typeof value === "object" && value !== null) {
            if (seen.has(value)) {
                if (options?.cloneReferences) {
                    return structuredClone(value);
                }
                return "[Circular]";
            }
            seen.add(value);
        }
        // Check if the key should be filtered out
        if (options?.filteredKeys?.includes(key)) {
            return undefined;
        }
        // If it is a BigInt
        if (typeof value === "bigint") {
            return value.toString();
        }
        // if it is a Regex
        if (value instanceof RegExp) {
            return value.toString();
        }
        // if it is a Set
        if (value instanceof Set) {
            return Array.from(value);
        }
        // if it is a Map, convert it to an object
        if (value instanceof Map) {
            const obj = {};
            value.forEach((v, k) => {
                obj[k] = v;
            });
            return obj;
        }
        return value;
    };
}
function makeSafeReviver(options) {
    if (!options) {
        return undefined;
    }
    return function reviver(key, value) {
        // Check if the key should be filtered out
        if (options?.filteredKeys?.includes(key)) {
            return undefined;
        }
        return value;
    };
}
function getPacketExtension(outputType) {
    switch (outputType) {
        case "application/json":
            return "json";
        case "application/super+json":
            return "json";
        case "text/plain":
            return "txt";
        default:
            return "txt";
    }
}
function safeJsonParse(value) {
    try {
        return JSON.parse(value);
    }
    catch {
        return;
    }
}
/**
 * Replaces the data in a SuperJSON-serialized string with new payload data while preserving
 * the original type metadata (Dates, BigInts, Sets, Maps, etc.).
 *
 * It is primarily useful for our run replay functionality where we want to preserve the original
 * type metadata for the new payload.
 *
 * Note that `undefined` type metadata is ignored when the corresponding field is overriden in the
 * new payload, i.e., fields which were previously undefined in the original payload are restored into
 * the primitive type they have in the new payload, instead of `undefined`.
 * This is a workaround for https://github.com/triggerdotdev/trigger.dev/issues/1968.
 *
 * @param original - A SuperJSON-serialized string containing the original data with type metadata
 * @param newPayload - A JSON string containing the new data to replace the original payload
 * @returns The deserialized object with new data but original type metadata preserved
 *
 * @throws {Error} If the newPayload is not valid JSON
 */
async function replaceSuperJsonPayload(original, newPayload) {
    const originalObject = superjson_js_1.default.parse(original);
    const newPayloadObject = JSON.parse(newPayload);
    const { meta } = superjson_js_1.default.serialize(originalObject);
    if (meta?.values) {
        const originalUndefinedKeys = Object.entries(meta.values)
            .filter(([, value]) => Array.isArray(value) && value.at(0) === "undefined")
            .map(([key]) => key);
        const overridenUndefinedKeys = originalUndefinedKeys.filter((key) => getKeyFromObject(newPayloadObject, key) !== undefined);
        overridenUndefinedKeys.forEach((key) => {
            delete meta.values[key];
        });
    }
    const newSuperJson = {
        json: newPayloadObject,
        meta,
    };
    return superjson_js_1.default.deserialize(newSuperJson);
}
function getKeyFromObject(object, key) {
    const jsonHeroPath = new path_1.JSONHeroPath(key);
    return jsonHeroPath.first(object);
}
/**
 * Detects if a superjson serialization contains circular references
 * by analyzing the meta.referentialEqualities structure.
 *
 * Based on superjson's ReferentialEqualityAnnotations type:
 * Record<string, string[]> | [string[]] | [string[], Record<string, string[]>]
 *
 * Circular references are represented as:
 * - [string[]] where strings are paths that reference back to root or ancestors
 * - The first element in [string[], Record<string, string[]>] format
 */
function hasCircularReference(meta) {
    if (!meta?.referentialEqualities) {
        return false;
    }
    const re = meta.referentialEqualities;
    // Case 1: [string[]] - array containing only circular references
    if (Array.isArray(re) && re.length === 1 && Array.isArray(re[0])) {
        return re[0].length > 0; // Has circular references
    }
    // Case 2: [string[], Record<string, string[]>] - mixed format
    if (Array.isArray(re) && re.length === 2 && Array.isArray(re[0])) {
        return re[0].length > 0; // First element contains circular references
    }
    // Case 3: Record<string, string[]> - check for circular patterns in shared references
    if (!Array.isArray(re) && typeof re === "object") {
        // Check if any reference path points to an ancestor path
        for (const [targetPath, referencePaths] of Object.entries(re)) {
            for (const refPath of referencePaths) {
                if (isCircularPattern(targetPath, refPath)) {
                    return true;
                }
            }
        }
        return false;
    }
    return false;
}
/**
 * Checks if a reference pattern represents a circular reference
 * by analyzing if the reference path points back to an ancestor of the target path
 */
function isCircularPattern(targetPath, referencePath) {
    const targetParts = targetPath.split(".");
    const refParts = referencePath.split(".");
    // For circular references, the reference path often contains the target path as a prefix
    // Example: targetPath="user", referencePath="user.details.user"
    // This means user.details.user points back to user (circular)
    // Check if reference path starts with target path + additional segments that loop back
    if (refParts.length > targetParts.length) {
        // Check if reference path starts with target path
        let isPrefix = true;
        for (let i = 0; i < targetParts.length; i++) {
            if (targetParts[i] !== refParts[i]) {
                isPrefix = false;
                break;
            }
        }
        // If reference path starts with target path and ends with target path,
        // it's likely a circular reference (e.g., "user" -> "user.details.user")
        if (isPrefix && refParts[refParts.length - 1] === targetParts[targetParts.length - 1]) {
            return true;
        }
    }
    return false;
}
//# sourceMappingURL=ioSerialization.js.map